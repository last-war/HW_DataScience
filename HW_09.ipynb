{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/last-war/HW_DataScience/blob/Homework-09/HW_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJIZXafsm5le"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/master/C1/W3/ungraded_labs/C1_W3_Lab_1_improving_accuracy_using_convolutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "В якості домашнього завдання вам пропонується створити нейронну мережу за допомогою механізмів Keras, яка буде класифікувати товари із датасету fasion_mnist.\n",
        "\n",
        "Вам належить запропонувати свою власну архітектуру мережі. Точність найнаївнішої, але адекватної нейромережі становить приблизно 91%. Точність вашої моделі повинна бути не нижчою за цей показник. Щоб досягти таких значень вам знадобиться поекспериментувати з гіперпараметрами мережі:\n",
        "\n",
        "кількість шарів;\n",
        "\n",
        "кількість нейронів;\n",
        "\n",
        "функції активації;\n",
        "\n",
        "кількість епох;\n",
        "\n",
        "розмір батчу;\n",
        "\n",
        "вибір оптимізатора;\n",
        "\n",
        "різні техніки регуляризації і т.д.\n",
        "\n",
        "Використайте вивчені техніки виявлення проблем навчання нейронної мережі, і потім поекспериментуйте.\n",
        "\n",
        "Рішення оформіть у вигляді окремого ноутбука."
      ],
      "metadata": {
        "id": "AdEn5wAFoa5a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnCNAG-VecJ9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# завантаження Fashion MNIST\n",
        "fmnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()\n",
        "\n",
        "# нормалізація\n",
        "training_images = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#перевірка сету\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "for itr in range(2):\n",
        "  id_pic = random.randint(0, test_images.shape[1])\n",
        "  plt.imshow(test_images[id_pic].reshape(28, 28), cmap=\"gray\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "D3UZNLZXVOzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для припинення навчання"
      ],
      "metadata": {
        "id": "HlFJBe1Oq2Se"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    '''\n",
        "    Halts the training after reaching 60 percent accuracy\n",
        "\n",
        "    Args:\n",
        "      epoch (integer) - index of epoch (required but unused in the function definition below)\n",
        "      logs (dict) - metric results from the training epoch\n",
        "    '''\n",
        "\n",
        "    # Check accuracy\n",
        "    if(logs.get('accuracy') > 0.98):\n",
        "      print(\"\\nGet is accuracy than 0.98 so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "    if(logs.get('loss') < 0.1):\n",
        "      print(\"\\nLoss is lower than 0.1 so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "# Instantiate class\n",
        "callbacks = myCallback()"
      ],
      "metadata": {
        "id": "0W5pfkr_q57U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimaze**\n",
        "\n",
        "tf.keras.optimizers.experimental.Adadelta(\n",
        "    learning_rate=0.001,\n",
        "    rho=0.95,\n",
        "    epsilon=1e-07,\n",
        "    weight_decay=None,\n",
        "    clipnorm=None,\n",
        "    clipvalue=None,\n",
        "    global_clipnorm=None,\n",
        "    use_ema=False,\n",
        "    ema_momentum=0.99,\n",
        "    ema_overwrite_frequency=None,\n",
        "    jit_compile=True,\n",
        "    name='Adadelta',\n",
        "    **kwargs\n",
        ")\n",
        "\n",
        "tf.keras.optimizers.experimental.RMSprop(\n",
        "    learning_rate=0.001,\n",
        "    rho=0.9,\n",
        "    momentum=0.0,\n",
        "    epsilon=1e-07,\n",
        "    centered=False,\n",
        "    weight_decay=None,\n",
        "    clipnorm=None,\n",
        "    clipvalue=None,\n",
        "    global_clipnorm=None,\n",
        "    use_ema=False,\n",
        "    ema_momentum=0.99,\n",
        "    ema_overwrite_frequency=100,\n",
        "    jit_compile=True,\n",
        "    name='RMSprop',\n",
        "    **kwargs\n",
        ")\n",
        "\n",
        "tf.keras.optimizers.experimental.SGD(\n",
        "    learning_rate=0.01,\n",
        "    momentum=0.0,\n",
        "    nesterov=False,\n",
        "    weight_decay=None,\n",
        "    clipnorm=None,\n",
        "    clipvalue=None,\n",
        "    global_clipnorm=None,\n",
        "    use_ema=False,\n",
        "    ema_momentum=0.99,\n",
        "    ema_overwrite_frequency=None,\n",
        "    jit_compile=True,\n",
        "    name='SGD',\n",
        "    **kwargs\n",
        ")\n",
        "\n",
        "tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.001,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    amsgrad=False,\n",
        "    weight_decay=None,\n",
        "    clipnorm=None,\n",
        "    clipvalue=None,\n",
        "    global_clipnorm=None,\n",
        "    use_ema=False,\n",
        "    ema_momentum=0.99,\n",
        "    ema_overwrite_frequency=None,\n",
        "    jit_compile=True,\n",
        "    name='Adam',\n",
        "    **kwargs\n",
        ")"
      ],
      "metadata": {
        "id": "2zTPyGt5ufN3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для всіх:\n",
        "\n",
        "батчі [10, 100, 500, 1000]\n",
        "\n",
        "епох [5, 10, 20, 50]\n",
        "\n",
        "4 оптимізаторів (вище)\n",
        "\n",
        "[Adadelta, RMSprop, SGD, Adam]\n",
        "\n",
        "func activ:\n",
        "\n",
        "relu(...) -  перевірити\n",
        "\n",
        "sigmoid(...) - перевірити\n",
        "\n",
        "softmax(...) - для фінального шару\n",
        "\n",
        "1) проста модель без згортання\n",
        "нейронів 784\n",
        "\n",
        "2) модель +1 згортання+зтискання\n",
        "\n",
        "3) + drops"
      ],
      "metadata": {
        "id": "s1J4AYsbteMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "l_optims = ['Adadelta', 'RMSprop', 'SGD', 'Adam']\n",
        "\n",
        "l_batchs = [100, 500, 1000]\n",
        "\n",
        "#по першій моделі і першому оптимізатору: прийняв рішення відкинути порції менше 100. Та зменшити максимальну кількість епох до 30\n",
        "#батч по 10 лише збільшує час навчання, без значного ефекту, як і велика кількість єпох\n",
        "#l_batchs = [10, 100, 500, 1000]\n",
        "#l_epochs = [5, 10, 20, 50]\n",
        "\n",
        "l_epochs = [10, 20, 30]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qffXwc9dXIPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_1\n",
        "# прохід для пошуку параметрів\n",
        "\n",
        "for cur_opt in l_optims:\n",
        "  for cur_epoch in l_epochs:\n",
        "    for cur_batch in l_batchs:\n",
        "      model = tf.keras.models.Sequential([\n",
        "              tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "              tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "              tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "                                          ])\n",
        "      model.compile(optimizer=cur_opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "      # Train the model\n",
        "      model.fit(training_images, training_labels, batch_size=cur_batch, epochs=cur_epoch, callbacks=[callbacks])\n",
        "\n",
        "      # Evaluate on the test set\n",
        "\n",
        "      test_loss = model.evaluate(test_images, test_labels)\n",
        "      print(f'\\nMODEL 1. optimizer={cur_opt} batch_size={cur_batch} epochs={cur_epoch}:')\n"
      ],
      "metadata": {
        "id": "hjrW-np-arqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adadelta максимально отримано на batch_size=100 epochs=50: 80%\n",
        "\n",
        "RMSprop максимально отримано на\n",
        "batch_size=100 epochs=20: 89%\n",
        "batch_size=500 epochs=20: 89%\n",
        "batch_size=500 epochs=50: 89%\n",
        "batch_size=1000 epochs=50: 89%\n",
        "\n",
        "SGD максимально отримано на\n",
        "batch_size=100 epochs=50: 86%\n",
        "\n",
        "Adam максимально отримано на\n",
        "batch_size=100 epochs=10: 89%\n",
        "batch_size=100 epochs=13/20: 88%\n",
        "batch_size=500 epochs=20: 89%\n",
        "batch_size=100 epochs=15/50: 88%\n",
        "batch_size=500 epochs=19/50: 89%\n",
        "batch_size=1000 epochs=25/50: 89%\n"
      ],
      "metadata": {
        "id": "JMHxmApxHuh-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Змінив параметри коллбеку до 0.1 втрат і 98 точність"
      ],
      "metadata": {
        "id": "ucWb3jAQRao2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model_1\n",
        "# контроль на обраних параметрах\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "        tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "                                    ])\n",
        "model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "print(f'\\nMODEL TRAINING:')\n",
        "history = model.fit(training_images, training_labels, batch_size=250, epochs=30, callbacks=[callbacks], validation_data=(test_images, test_labels))\n",
        "\n",
        "\n",
        "# Plot the results\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4gn1Scy93P_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_2\n",
        "\n",
        "for cur_opt in l_optims:\n",
        "  for cur_epoch in l_epochs:\n",
        "    for cur_batch in l_batchs:\n",
        "      model = tf.keras.models.Sequential([\n",
        "              tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "              tf.keras.layers.MaxPooling2D(2, 2),\n",
        "              tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "              tf.keras.layers.MaxPooling2D(2,2),\n",
        "              tf.keras.layers.Flatten(),\n",
        "              tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "              tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "                                          ])\n",
        "      model.compile(optimizer=cur_opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "      # Train the model\n",
        "      model.fit(training_images, training_labels, batch_size=cur_batch, epochs=cur_epoch, callbacks=[callbacks])\n",
        "\n",
        "      # Evaluate on the test set\n",
        "      test_loss = model.evaluate(test_images, test_labels)\n",
        "      print(f'\\nMODEL 1. optimizer={cur_opt} batch_size={cur_batch} epochs={cur_epoch}:')\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "OFLlAUjnauHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "висновки\n",
        "Швикість роботи збільшено, результати співставні і краще\n",
        "\n",
        "\n",
        "Adadelta максимально отримано на batch_size=100 epochs=30: 71%\n",
        "(стало гірше швидкість навчання вища, даний оптимізатор не підходить для таких задач)\n",
        "\n",
        "RMSprop максимально отримано на batch_size=100-500 epochs=20-30: 91%\n",
        "(високий результат, але помітна помилка на валідаційних даних)\n",
        "\n",
        "SGD максимально отримано на batch_size=100 epochs=30: 88%\n",
        "(результат краще, проте цей оптимізатор не відповідає задачі)\n",
        "\n",
        "Adam максимально отримано на batch_size=100-500 epochs=20-30: 91%\n",
        "(ідентично до RMS, навіть на наявних набор при валідації значно зростають втрати. Великий ризик перенавчання)\n"
      ],
      "metadata": {
        "id": "BnliKnAp9AHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model_2\n",
        "# контроль на обраних параметрах\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "                                    ])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "print(f'\\nMODEL TRAINING:')\n",
        "history = model.fit(training_images, training_labels, batch_size=250, epochs=25, callbacks=[callbacks], validation_data=(test_images, test_labels))\n",
        "\n",
        "\n",
        "# Plot the results\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TNPjt0i29Ct1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_3 add drops\n",
        "\n",
        "for cur_opt in l_optims:\n",
        "  for cur_epoch in l_epochs:\n",
        "    for cur_batch in l_batchs:\n",
        "      model = tf.keras.models.Sequential([\n",
        "              tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "              tf.keras.layers.MaxPooling2D(2, 2),\n",
        "              tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "              tf.keras.layers.MaxPooling2D(2,2),\n",
        "              tf.keras.layers.Dropout(0.1),\n",
        "              tf.keras.layers.Flatten(),\n",
        "              tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "              tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "                                          ])\n",
        "      model.compile(optimizer=cur_opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "      # Train the model\n",
        "      model.fit(training_images, training_labels, batch_size=cur_batch, epochs=cur_epoch, callbacks=[callbacks])\n",
        "\n",
        "      # Evaluate on the test set\n",
        "      test_loss = model.evaluate(test_images, test_labels)\n",
        "      print(f'\\nMODEL 3. optimizer={cur_opt} batch_size={cur_batch} epochs={cur_epoch}:')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GkRZfX_FN2gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "висновки Швикість роботи співставна, результати певних оптимізаторів стали гірше\n",
        "\n",
        "Adadelta максимально отримано на batch_size=100 epochs=30: 73% (майже ідентично, даний оптимізатор не підходить для таких задач)\n",
        "\n",
        "RMSprop максимально отримано на batch_size=500 epochs=30: 92% (високий результат, при тому що тестова вибірка дає 96%)\n",
        "\n",
        "SGD максимально отримано на batch_size=100 epochs=30: 88% (результат ідентичний, проте цей оптимізатор не відповідає задачі)\n",
        "\n",
        "Adam максимально отримано на batch_size=500 epochs=30: 92% (найкращий результат на валідаційних даних)\n"
      ],
      "metadata": {
        "id": "aIFI9KfhXWYG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0tFgT1MMKi6"
      },
      "outputs": [],
      "source": [
        "# model 3 оптимальні параметри\n",
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "        tf.keras.layers.Dropout(0.1),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "                                    ])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "print(f'\\nMODEL TRAINING:')\n",
        "history = model.fit(training_images, training_labels, batch_size=500, epochs=30, callbacks=[callbacks], validation_data=(test_images, test_labels))\n",
        "\n",
        "\n",
        "\n",
        "# Plot the results\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Хочу додатково перевірити кілька вариантів без коллбеку, але з іншою кількостю нейронів\n",
        "відносно великою і відносно малою"
      ],
      "metadata": {
        "id": "B8vMqudiZKKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model 3 але мало нейронів\n",
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "        tf.keras.layers.Dropout(0.1),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "                                    ])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "print(f'\\nMODEL TRAINING:')\n",
        "history = model.fit(training_images, training_labels, batch_size=500, epochs=50, validation_data=(test_images, test_labels))\n",
        "\n",
        "\n",
        "\n",
        "# Plot the results\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy 64-10')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Mn7fbXnQZjba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8TrRge6Zjte"
      },
      "outputs": [],
      "source": [
        "# model 3 але багато нейронів +доп рівень\n",
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "        tf.keras.layers.Dropout(0.1),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "                                    ])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "print(f'\\nMODEL TRAINING:')\n",
        "history = model.fit(training_images, training_labels, batch_size=500, epochs=50, validation_data=(test_images, test_labels))\n",
        "\n",
        "\n",
        "\n",
        "# Plot the results\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy 512-256-10')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Збільшена кількість шарів та нейронів прямий шлях до перенавчання (якщо мова про цей сет з розмірностю 28*28)\n",
        "варіація з 64 нейронами вже з 10 епох дала результати понад 90% на валідаційному наборі\n",
        "Оптимізатор, для завдань розпізнання - Адам.\n",
        "Функція софтмакс - так як класів понад 2\n",
        "щодо батчу - на мою думку 1/500 від виборки оптимальний варіант. Це дає достатню швидкість при цього вибірки вистачає для визначення коєф.\n",
        "Кількість епох варто обмежувати на рівні 30-50, але краще використовувати перевірку точності та втрат, для припинення навчання.\n",
        "Щодо перенавчання: на такому малому наборі його не уникнути, але можна зменшити, шляхом як дропу, так і перериванням навчання"
      ],
      "metadata": {
        "id": "wL6MYpaJa3IY"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}