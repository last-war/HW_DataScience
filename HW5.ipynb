{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1jPSR5p3ojZvrgEMYywT996f8eFgDdvvx",
      "authorship_tag": "ABX9TyM33Ty3dJYJ51Zu2E+LJ1RZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/last-war/HW_DataScience/blob/Homework-05/HW5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В домашньому завданні до даного модулю ви потренуєтесь робити тестове завдання для влаштування на роботу. За даними акселерометра з мобільного телефону потрібно класифікувати, якою діяльністю займається людина: йде, стоїть, біжить чи йде по сходах. Знайти датасет ви можете за посиланням.\n",
        "\n",
        "Використайте алгоритми SVM та випадковий ліс з бібліотеки scikit-learn. Як характеристики можете брати показники з акселерометра, проте щоб покращити результати роботи алгоритмів, спочатку можна підготувати наш датасет і розрахувати часові ознаки (time domain features). Більше ці характеристики описані в даній статті.\n",
        "\n",
        "Порівняйте результати роботи обох алгоритмів на різних фічах та різні моделі між собою."
      ],
      "metadata": {
        "id": "sJFey5gfOM86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "C_RYxSiQ0KNy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "підготовка датасету\n",
        "\n",
        "створення з кожного файлу набору ознак\n",
        "\n",
        "результат записати у файл\n",
        "\n",
        "для налогодження розкоментувати строку запису"
      ],
      "metadata": {
        "id": "XQuLXVs4XvBO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gZF1jP_BOFn5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "\n",
        "genway = '/content/drive/MyDrive/Colab Notebooks/data'\n",
        "\n",
        "gen_df = pd.DataFrame()\n",
        "\n",
        "paths = ['idle', 'running', 'stairs', 'walking']\n",
        "\n",
        "all_df = []\n",
        "for catname in paths:\n",
        "    iter = 1\n",
        "\n",
        "    fname = genway+'/'+catname+'/'+catname+'-'+str(iter)+'.csv'\n",
        "    while os.path.exists(fname):\n",
        "        f_df = pd.read_csv(fname)\n",
        "        clean_df = pd.DataFrame()\n",
        "        clean_df['type'] = [catname]\n",
        "        clean_df['name'] = catname+'-'+str(iter)\n",
        "        clean_df['mean_acc_X'] = f_df['accelerometer_X'].mean()\n",
        "        clean_df['mean_acc_Y'] = f_df['accelerometer_Y'].mean()\n",
        "        clean_df['mean_acc_Z'] = f_df['accelerometer_Z'].mean()\n",
        "        clean_df['variance_acc_X'] = f_df['accelerometer_X'].var()\n",
        "        clean_df['variance_acc_Y'] = f_df['accelerometer_Y'].var()\n",
        "        clean_df['variance_acc_Z'] = f_df['accelerometer_Z'].var()\n",
        "        clean_df['std_acc_X'] = f_df['accelerometer_X'].std()\n",
        "        clean_df['std_acc_Y'] = f_df['accelerometer_Y'].std()\n",
        "        clean_df['std_acc_Z'] = f_df['accelerometer_Z'].std()\n",
        "        clean_df['median_acc_X'] = f_df['accelerometer_X'].median()\n",
        "        clean_df['median_acc_Y'] = f_df['accelerometer_Y'].median()\n",
        "        clean_df['median_acc_Z'] = f_df['accelerometer_Z'].median()\n",
        "        clean_df['max_acc_X'] = f_df['accelerometer_X'].max()\n",
        "        clean_df['max_acc_Y'] = f_df['accelerometer_Y'].max()\n",
        "        clean_df['max_acc_Z'] = f_df['accelerometer_Z'].max()\n",
        "        clean_df['min_acc_X'] = f_df['accelerometer_X'].min()\n",
        "        clean_df['min_acc_Y'] = f_df['accelerometer_Y'].min()\n",
        "        clean_df['min_acc_Z'] = f_df['accelerometer_Z'].min()\n",
        "        clean_df['rms_acc_X'] = np.sqrt(np.mean(f_df['accelerometer_X']**2))\n",
        "        clean_df['rms_acc_Y'] = np.sqrt(np.mean(f_df['accelerometer_Y']**2))\n",
        "        clean_df['rms_acc_Z'] = np.sqrt(np.mean(f_df['accelerometer_Z']**2))\n",
        "        clean_df['sma_acc_X'] = np.sum(np.abs(f_df['accelerometer_X']), axis=0)\n",
        "        clean_df['sma_acc_Y'] = np.sum(np.abs(f_df['accelerometer_Y']), axis=0)\n",
        "        clean_df['sma_acc_Z'] = np.sum(np.abs(f_df['accelerometer_Z']), axis=0)\n",
        "        clean_df['idxmin_acc_X'] = f_df['accelerometer_X'].idxmin()\n",
        "        clean_df['idxmin_acc_Y'] = f_df['accelerometer_Y'].idxmin()\n",
        "        clean_df['idxmin_acc_Z'] = f_df['accelerometer_Z'].idxmin()\n",
        "        clean_df['idxmax_acc_X'] = f_df['accelerometer_X'].idxmax()\n",
        "        clean_df['idxmax_acc_Y'] = f_df['accelerometer_Y'].idxmax()\n",
        "        clean_df['idxmax_acc_Z'] = f_df['accelerometer_Z'].idxmax()\n",
        "        clean_df['kurtosis_acc_X'] = f_df['accelerometer_X'].kurtosis()\n",
        "        clean_df['kurtosis_acc_Y'] = f_df['accelerometer_Y'].kurtosis()\n",
        "        clean_df['kurtosis_acc_Z'] = f_df['accelerometer_Z'].kurtosis()\n",
        "        clean_df['skewness_acc_X'] = f_df['accelerometer_X'].skew()\n",
        "        clean_df['skewness_acc_Y'] = f_df['accelerometer_Y'].skew()\n",
        "        clean_df['skewness_acc_Z'] = f_df['accelerometer_Z'].skew()\n",
        "        clean_df['mad_acc_X'] = (f_df['accelerometer_X'] - f_df['accelerometer_X'].mean()).abs().mean()\n",
        "        clean_df['mad_acc_Y'] = (f_df['accelerometer_Y'] - f_df['accelerometer_Y'].mean()).abs().mean()\n",
        "        clean_df['mad_acc_Z'] = (f_df['accelerometer_Z'] - f_df['accelerometer_Z'].mean()).abs().mean()\n",
        "        clean_df['power_acc_X'] = np.mean(f_df['accelerometer_X']**2)\n",
        "        clean_df['power_acc_Y'] = np.mean(f_df['accelerometer_Y']**2)\n",
        "        clean_df['power_acc_Z'] = np.mean(f_df['accelerometer_Z']**2)\n",
        "        clean_df['energy_acc_X'] = np.sum(f_df['accelerometer_X']**2)\n",
        "        clean_df['energy_acc_Y'] = np.sum(f_df['accelerometer_Y']**2)\n",
        "        clean_df['energy_acc_Z'] = np.sum(f_df['accelerometer_Z']**2)\n",
        "        clean_df['iqr_acc_X'] = f_df['accelerometer_X'].quantile(0.75) - f_df['accelerometer_X'].quantile(0.25)\n",
        "        clean_df['iqr_acc_Y'] = f_df['accelerometer_Y'].quantile(0.75) - f_df['accelerometer_Y'].quantile(0.25)\n",
        "        clean_df['iqr_acc_Z'] = f_df['accelerometer_Z'].quantile(0.75) - f_df['accelerometer_Z'].quantile(0.25)\n",
        "\n",
        "        all_df.append(clean_df)\n",
        "        fname = genway+'/'+catname+'/'+catname+'-'+str(iter)+'.csv'\n",
        "        iter += 1\n",
        "gen_df = pd.concat(all_df)\n",
        "#gen_df.to_csv(genway+\"/clean_data.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Підготовка тренувального сету\n",
        "\n",
        "підготовка тестового сету\n",
        "\n",
        "всі ознаки в колонках 2++\n",
        "\n",
        "цільова ознака в колонці тайп\n",
        "\n",
        "вивід розмірностей"
      ],
      "metadata": {
        "id": "3z2Jck3VYjFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.multiarray import where\n",
        "gen_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/clean_data.csv')\n",
        "\n",
        "\n",
        "gen_df['type'] = np.where(gen_df['type'] == 'idle',0 , np.where(gen_df['type'] == 'running',1 , np.where(gen_df['type'] == 'stairs',2 , 3)))\n",
        "\n",
        "\n",
        "W_train, W_test, type_train, type_test = train_test_split(gen_df.iloc[0:,2:], gen_df['type'], test_size=0.2, stratify=gen_df['type'])\n",
        "\n",
        "\n",
        "W_train.shape, W_test.shape, type_train.shape, type_test.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tL2hB2QuOnl",
        "outputId": "d0622cac-366a-43ba-fb65-93f4afabcf51"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5172, 48), (1294, 48), (5172,), (1294,))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "створення модели SVC версія поліном\n",
        "\n",
        "задати С та ступінь списками\n",
        "\n",
        "виконати навчання на тренувальному сеті в циклі\n",
        "\n",
        "оцінка по метриці ф1"
      ],
      "metadata": {
        "id": "u1wYlVFEZ8QD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Cs = [0.01, 0.1, 1., 10., 100.]\n",
        "degrees = [2, 3, 4]\n",
        "\n",
        "for C in Cs:\n",
        "    for degree in degrees:\n",
        "        svc_poly = SVC(kernel=\"poly\", degree=degree, C=C, probability=True).fit(W_train, type_train)\n",
        "\n",
        "        type_train_predict = np.round(svc_poly.predict_proba(W_train)[:, 1]).astype(int)\n",
        "        type_test_predict = np.round(svc_poly.predict_proba(W_test)[:, 1]).astype(int)\n",
        "\n",
        "        metric_train = f1_score(type_train, type_train_predict, average='micro')\n",
        "        metric_test = f1_score(type_test, type_test_predict, average='micro')\n",
        "\n",
        "        print(f\"{C=}, {degree=}, {metric_train=:.2f}, {metric_test=:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avycieIHZ7N1",
        "outputId": "2d3c52ec-351c-4f71-f2c5-2ad59bc225d7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C=0.01, degree=2, metric_train=0.66, metric_test=0.654\n",
            "C=0.01, degree=3, metric_train=0.66, metric_test=0.648\n",
            "C=0.01, degree=4, metric_train=0.66, metric_test=0.641\n",
            "C=0.1, degree=2, metric_train=0.67, metric_test=0.664\n",
            "C=0.1, degree=3, metric_train=0.67, metric_test=0.662\n",
            "C=0.1, degree=4, metric_train=0.67, metric_test=0.658\n",
            "C=1.0, degree=2, metric_train=0.67, metric_test=0.668\n",
            "C=1.0, degree=3, metric_train=0.67, metric_test=0.663\n",
            "C=1.0, degree=4, metric_train=0.67, metric_test=0.661\n",
            "C=10.0, degree=2, metric_train=0.68, metric_test=0.673\n",
            "C=10.0, degree=3, metric_train=0.67, metric_test=0.669\n",
            "C=10.0, degree=4, metric_train=0.67, metric_test=0.662\n",
            "C=100.0, degree=2, metric_train=0.68, metric_test=0.686\n",
            "C=100.0, degree=3, metric_train=0.68, metric_test=0.682\n",
            "C=100.0, degree=4, metric_train=0.68, metric_test=0.678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "залишаю параметри\n",
        "\n",
        "C=100.0, degree=2"
      ],
      "metadata": {
        "id": "pxKUnRtSqgSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svc_poly = SVC(kernel=\"poly\", degree=2, C=100, probability=True).fit(W_train, type_train)\n",
        "svc_poly.n_iter_, svc_poly.intercept_, svc_poly.n_features_in_, svc_poly.feature_names_in_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EADADQs6tD1F",
        "outputId": "40984506-2a5c-4cc5-abf0-858edf466a9f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([   40,    13,    10,   463,  5998, 25348], dtype=int32),\n",
              " array([ 2.12076136,  2.12013443,  1.87130898, -2.959278  , -1.13623618,\n",
              "        -0.96730163]),\n",
              " 48,\n",
              " array(['mean_acc_X', 'mean_acc_Y', 'mean_acc_Z', 'variance_acc_X',\n",
              "        'variance_acc_Y', 'variance_acc_Z', 'std_acc_X', 'std_acc_Y',\n",
              "        'std_acc_Z', 'median_acc_X', 'median_acc_Y', 'median_acc_Z',\n",
              "        'max_acc_X', 'max_acc_Y', 'max_acc_Z', 'min_acc_X', 'min_acc_Y',\n",
              "        'min_acc_Z', 'rms_acc_X', 'rms_acc_Y', 'rms_acc_Z', 'sma_acc_X',\n",
              "        'sma_acc_Y', 'sma_acc_Z', 'idxmin_acc_X', 'idxmin_acc_Y',\n",
              "        'idxmin_acc_Z', 'idxmax_acc_X', 'idxmax_acc_Y', 'idxmax_acc_Z',\n",
              "        'kurtosis_acc_X', 'kurtosis_acc_Y', 'kurtosis_acc_Z',\n",
              "        'skewness_acc_X', 'skewness_acc_Y', 'skewness_acc_Z', 'mad_acc_X',\n",
              "        'mad_acc_Y', 'mad_acc_Z', 'power_acc_X', 'power_acc_Y',\n",
              "        'power_acc_Z', 'energy_acc_X', 'energy_acc_Y', 'energy_acc_Z',\n",
              "        'iqr_acc_X', 'iqr_acc_Y', 'iqr_acc_Z'], dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "для моделі ліс пошук n_estimators"
      ],
      "metadata": {
        "id": "TuNybNsJfdXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_estimators = [3, 5, 10, 50, 100, 200]\n",
        "\n",
        "for estimator in n_estimators:\n",
        "\n",
        "    model = RandomForestClassifier(n_estimators=estimator)\n",
        "\n",
        "    model.fit(W_train, type_train)\n",
        "\n",
        "    metric_train = f1_score(type_train, np.round(model.predict(W_train)).astype(int), average='micro')\n",
        "    metric_test = f1_score(type_test, np.round(model.predict(W_test)).astype(int), average='micro')\n",
        "    print(f\"{estimator=}, {metric_train=:.2f}, {metric_test=:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nf0i_pEm59mn",
        "outputId": "ff61c1aa-bd00-49ac-92ac-4213f45653b1"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "estimator=3, metric_train=1.00, metric_test=0.998\n",
            "estimator=5, metric_train=1.00, metric_test=0.999\n",
            "estimator=10, metric_train=1.00, metric_test=0.998\n",
            "estimator=50, metric_train=1.00, metric_test=0.998\n",
            "estimator=100, metric_train=1.00, metric_test=0.998\n",
            "estimator=200, metric_train=1.00, metric_test=0.998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "змінив критерій для перевірки"
      ],
      "metadata": {
        "id": "V4Lg6_6PyuZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_estimators = [3, 5, 10, 50, 100, 200]\n",
        "\n",
        "for estimator in n_estimators:\n",
        "\n",
        "    model = RandomForestClassifier(n_estimators=estimator, criterion='log_loss')\n",
        "\n",
        "    model.fit(W_train, type_train)\n",
        "\n",
        "    metric_train = f1_score(type_train, np.round(model.predict(W_train)).astype(int), average='micro')\n",
        "    metric_test = f1_score(type_test, np.round(model.predict(W_test)).astype(int), average='micro')\n",
        "    print(f\"{estimator=}, {metric_train=:.2f}, {metric_test=:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sa0maN1hytum",
        "outputId": "f9916f04-3b88-43bb-8b50-93a451419844"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "estimator=3, metric_train=1.00, metric_test=0.995\n",
            "estimator=5, metric_train=1.00, metric_test=0.997\n",
            "estimator=10, metric_train=1.00, metric_test=0.998\n",
            "estimator=50, metric_train=1.00, metric_test=0.999\n",
            "estimator=100, metric_train=1.00, metric_test=0.999\n",
            "estimator=200, metric_train=1.00, metric_test=1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "модель SVC більш адекватна. рандом форест навіть при змінах показує ознаки перенавчання"
      ],
      "metadata": {
        "id": "bEOr9FQGzMCP"
      }
    }
  ]
}