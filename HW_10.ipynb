{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/last-war/HW_DataScience/blob/Homework-10/HW_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJIZXafsm5le"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/master/C1/W3/ungraded_labs/C1_W3_Lab_1_improving_accuracy_using_convolutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Частина 1\n",
        "В якості домашнього завдання вам пропонується створити нейронну мережу за допомогою механізмів Keras, яка буде класифікувати товари із датасету fasion_mnist.\n",
        "\n",
        "На відміну від попереднього завдання вам пропонується створити згорткову нейромережу. Підберіть архітектуру мережі та навчіть її на даних із датасету fasion_mnist. Спробуйте досягти максимально можливої точності класифікації за рахунок маніпуляції параметрами мережі. Порівняйте точність отриманої згорткової мережі з точністю багатошарової мережі з попереднього завдання. Зробіть висновки."
      ],
      "metadata": {
        "id": "AdEn5wAFoa5a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnCNAG-VecJ9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# завантаження Fashion MNIST\n",
        "fmnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()\n",
        "\n",
        "# нормалізація\n",
        "training_images = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#перевірка сету\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "for itr in range(2):\n",
        "  id_pic = random.randint(0, test_images.shape[1])\n",
        "  plt.imshow(test_images[id_pic].reshape(28, 28), cmap=\"gray\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "D3UZNLZXVOzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для припинення навчання"
      ],
      "metadata": {
        "id": "HlFJBe1Oq2Se"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    '''\n",
        "    Halts the training after reaching 60 percent accuracy\n",
        "\n",
        "    Args:\n",
        "      epoch (integer) - index of epoch (required but unused in the function definition below)\n",
        "      logs (dict) - metric results from the training epoch\n",
        "    '''\n",
        "\n",
        "    if(logs.get('accuracy') > 0.99):\n",
        "      print(\"\\nGet is accuracy than 0.99 so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "    if(logs.get('loss') < 0.01):\n",
        "      print(\"\\nLoss is lower than 0.01 so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "# Instantiate class\n",
        "callbacks = myCallback()"
      ],
      "metadata": {
        "id": "0W5pfkr_q57U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2zTPyGt5ufN3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для всіх:\n",
        "\n",
        "батчі [100, 250, 500]\n",
        "\n",
        "[RMSprop, Adam]\n",
        "\n",
        "1) модель 1 згортання+зтискання\n",
        "\n",
        "2) модель 2 згортання+зтискання\n",
        "\n",
        "3) модель 3 згортання+зтискання\n",
        "\n",
        "4) модель 4 згортання+зтискання\n",
        "\n",
        "5) + drops (для найкращої)"
      ],
      "metadata": {
        "id": "s1J4AYsbteMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l_optims = ['RMSprop', 'Adam']\n",
        "\n",
        "l_batchs = [100, 250, 500]\n",
        "\n",
        "rez_dict = {\n",
        "    'model_1': {'optim':'', 'batch':0, 'epoch':0, 'acc':0.0},\n",
        "    'model_2': {'optim':'', 'batch':0, 'epoch':0, 'acc':0.0},\n",
        "    'model_3': {'optim':'', 'batch':0, 'epoch':0, 'acc':0.0},\n",
        "    'model_4': {'optim':'', 'batch':0, 'epoch':0, 'acc':0.0},\n",
        "    'model_5': {'optim':'', 'batch':0, 'epoch':0, 'acc':0.0},\n",
        "    'model_6': {'optim':'', 'batch':0, 'epoch':0, 'acc':0.0},\n",
        "            }"
      ],
      "metadata": {
        "id": "qffXwc9dXIPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model: 1cov_1plot_0drop_196-98-10\n",
        "rec = rez_dict['model_1']\n",
        "# прохід для пошуку параметрів\n",
        "\n",
        "for cur_opt in l_optims:\n",
        "    for cur_batch in l_batchs:\n",
        "      model = tf.keras.models.Sequential([\n",
        "              tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "              #26*26\n",
        "              tf.keras.layers.MaxPooling2D(2, 2),\n",
        "              #14*14\n",
        "              tf.keras.layers.Flatten(),\n",
        "              tf.keras.layers.Dense(196, activation=tf.nn.relu),\n",
        "              tf.keras.layers.Dense(98, activation=tf.nn.relu),\n",
        "              tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "                                          ])\n",
        "      model.compile(optimizer=cur_opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "      # Train the model\n",
        "      history = model.fit(training_images, training_labels, batch_size=cur_batch, epochs=50, callbacks=[callbacks])\n",
        "\n",
        "      # Evaluate on the test set\n",
        "      test_accuracy = model.evaluate(test_images, test_labels)\n",
        "      print(f'\\nMODEL 1. optimizer={cur_opt} batch_size={cur_batch}:')\n",
        "\n",
        "\n",
        "      #results\n",
        "      if rec['acc'] < test_accuracy[-1]:\n",
        "        rec['optim'] = cur_opt\n",
        "        rec['batch'] = cur_batch\n",
        "        rec['epoch'] = len(history.history['accuracy'])\n",
        "        rec['acc'] = test_accuracy[-1]\n",
        "\n",
        "print(rec)"
      ],
      "metadata": {
        "id": "hjrW-np-arqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL 1. optimizer=Adam batch_size=500:\n",
        "{'optim': 'RMSprop', 'batch': 500, 'epoch': 39, 'acc': 0.9164000153541565}"
      ],
      "metadata": {
        "id": "JMHxmApxHuh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model: 2cov_2plot_0drop_288-144-10\n",
        "rec = rez_dict['model_2']\n",
        "# прохід для пошуку параметрів\n",
        "\n",
        "for cur_opt in l_optims:\n",
        "    for cur_batch in l_batchs:\n",
        "      model = tf.keras.models.Sequential([\n",
        "              tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "              #26*26\n",
        "              tf.keras.layers.MaxPooling2D(2, 2),\n",
        "              #14*14\n",
        "              tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "              #12*12\n",
        "              tf.keras.layers.MaxPooling2D(2, 2),\n",
        "              #6*6\n",
        "              tf.keras.layers.Flatten(),\n",
        "              tf.keras.layers.Dense(288, activation=tf.nn.relu),\n",
        "              tf.keras.layers.Dense(144, activation=tf.nn.relu),\n",
        "              tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "                                          ])\n",
        "      model.compile(optimizer=cur_opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "      # Train the model\n",
        "      history = model.fit(training_images, training_labels, batch_size=cur_batch, epochs=50, callbacks=[callbacks])\n",
        "\n",
        "      # Evaluate on the test set\n",
        "      test_accuracy = model.evaluate(test_images, test_labels)\n",
        "      print(f'\\nMODEL 2cov_2plot_0drop_288-144-10. optimizer={cur_opt} batch_size={cur_batch}:')\n",
        "\n",
        "\n",
        "      #results\n",
        "      if rec['acc'] < test_accuracy[-1]:\n",
        "        rec['optim'] = cur_opt\n",
        "        rec['batch'] = cur_batch\n",
        "        rec['epoch'] = len(history.history['accuracy'])\n",
        "        rec['acc'] = test_accuracy[-1]\n",
        "\n",
        "print(rec)\n"
      ],
      "metadata": {
        "id": "4gn1Scy93P_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL 2. optimizer=Adam batch_size=500:\n",
        "{'optim': 'RMSprop', 'batch': 500, 'epoch': 50, 'acc': 0.9103999733924866}"
      ],
      "metadata": {
        "id": "V1uO7PWbkVki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model: 2cov5_2plot_0drop_-512-256-10\n",
        "rec = rez_dict['model_3']\n",
        "# прохід для пошуку параметрів\n",
        "\n",
        "for cur_opt in l_optims:\n",
        "    for cur_batch in l_batchs:\n",
        "      model = tf.keras.models.Sequential([\n",
        "              tf.keras.layers.Conv2D(32, (5,5), activation='relu', input_shape=(28, 28, 1)),\n",
        "              #24*24\n",
        "              tf.keras.layers.MaxPooling2D(2, 2),\n",
        "              #12*12\n",
        "              tf.keras.layers.Conv2D(64, (5,5), activation='relu'),\n",
        "              #8*8\n",
        "              tf.keras.layers.MaxPooling2D(2, 2),\n",
        "              #4*4\n",
        "              tf.keras.layers.Flatten(),\n",
        "              tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "              tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "              tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "                                          ])\n",
        "      model.compile(optimizer=cur_opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "      # Train the model\n",
        "      history = model.fit(training_images, training_labels, batch_size=cur_batch, epochs=50, callbacks=[callbacks])\n",
        "\n",
        "      # Evaluate on the test set\n",
        "      test_accuracy = model.evaluate(test_images, test_labels)\n",
        "      print(f'\\nMODEL 3. 2cov5_2plot_0drop_-512-256-10. optimizer={cur_opt} batch_size={cur_batch}:')\n",
        "\n",
        "\n",
        "      #results\n",
        "      if rec['acc'] < test_accuracy[-1]:\n",
        "        rec['optim'] = cur_opt\n",
        "        rec['batch'] = cur_batch\n",
        "        rec['epoch'] = len(history.history['accuracy'])\n",
        "        rec['acc'] = test_accuracy[-1]\n",
        "\n",
        "print(rec)\n"
      ],
      "metadata": {
        "id": "OFLlAUjnauHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL 3. 2cov5_2plot_0drop_-512-256-10. optimizer=Adam batch_size=500:\n",
        "{'optim': 'Adam', 'batch': 500, 'epoch': 35, 'acc': 0.916700005531311}"
      ],
      "metadata": {
        "id": "BnliKnAp9AHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model: 2cov3_2plot_0drop_-256-128-64-10\n",
        "rec = rez_dict['model_4']\n",
        "# прохід для пошуку параметрів\n",
        "\n",
        "for cur_opt in l_optims:\n",
        "    for cur_batch in l_batchs:\n",
        "      model = tf.keras.models.Sequential([\n",
        "              tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "              #26*26\n",
        "              tf.keras.layers.MaxPooling2D(2, 2),\n",
        "              #13*13\n",
        "              tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "              #11*11\n",
        "              tf.keras.layers.MaxPooling2D(2, 2),\n",
        "              #5*5\n",
        "              tf.keras.layers.Flatten(),\n",
        "              tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "              tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "              tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "              tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "                                          ])\n",
        "      model.compile(optimizer=cur_opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "      # Train the model\n",
        "      history = model.fit(training_images, training_labels, batch_size=cur_batch, epochs=50, callbacks=[callbacks])\n",
        "\n",
        "      # Evaluate on the test set\n",
        "      test_accuracy = model.evaluate(test_images, test_labels)\n",
        "      print(f'\\nMODEL 4. 2cov5_2plot_0drop_-512-256-10. optimizer={cur_opt} batch_size={cur_batch}:')\n",
        "\n",
        "\n",
        "      #results\n",
        "      if rec['acc'] < test_accuracy[-1]:\n",
        "        rec['optim'] = cur_opt\n",
        "        rec['batch'] = cur_batch\n",
        "        rec['epoch'] = len(history.history['accuracy'])\n",
        "        rec['acc'] = test_accuracy[-1]\n",
        "\n",
        "print(rec)"
      ],
      "metadata": {
        "id": "TNPjt0i29Ct1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL 4. 2cov5_2plot_0drop_-512-256-10. optimizer=Adam batch_size=500:\n",
        "{'optim': 'RMSprop', 'batch': 500, 'epoch': 38, 'acc': 0.9150000214576721}\n"
      ],
      "metadata": {
        "id": "YphBuEpIJQII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model: 2cov3_2plot_1drop_-512-256-128-10\n",
        "rec = rez_dict['model_5']\n",
        "# прохід для пошуку параметрів\n",
        "\n",
        "for cur_opt in l_optims:\n",
        "    for cur_batch in l_batchs:\n",
        "      model = tf.keras.models.Sequential([\n",
        "              tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "              #26*26\n",
        "              tf.keras.layers.MaxPooling2D(2, 2),\n",
        "              #13*13\n",
        "              tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "              #11*11\n",
        "              tf.keras.layers.MaxPooling2D(2, 2),\n",
        "              #5*5\n",
        "              tf.keras.layers.Dropout(0.2),\n",
        "              tf.keras.layers.Flatten(),\n",
        "              tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "              tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "              tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "              tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "                                          ])\n",
        "      model.compile(optimizer=cur_opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "      # Train the model\n",
        "      history = model.fit(training_images, training_labels, batch_size=cur_batch, epochs=50, callbacks=[callbacks])\n",
        "\n",
        "      # Evaluate on the test set\n",
        "      test_accuracy = model.evaluate(test_images, test_labels)\n",
        "      print(f'\\nMODEL 5. 2cov5_2plot_1drop_-512-256-128-10. optimizer={cur_opt} batch_size={cur_batch}:')\n",
        "\n",
        "\n",
        "      #results\n",
        "      if rec['acc'] < test_accuracy[-1]:\n",
        "        rec['optim'] = cur_opt\n",
        "        rec['batch'] = cur_batch\n",
        "        rec['epoch'] = len(history.history['accuracy'])\n",
        "        rec['acc'] = test_accuracy[-1]\n",
        "\n",
        "print(rec)"
      ],
      "metadata": {
        "id": "GkRZfX_FN2gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "MODEL 5. 2cov5_2plot_1drop_-512-256-128-10. optimizer=Adam batch_size=500:\n",
        "{'optim': 'Adam', 'batch': 100, 'epoch': 38, 'acc': 0.9180999994277954}"
      ],
      "metadata": {
        "id": "aIFI9KfhXWYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Збільшу кількість пост шарів, да величину дропу"
      ],
      "metadata": {
        "id": "B8vMqudiZKKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model: 2cov3_2plot_1drop_-1024-512-256-128-64-10\n",
        "rec = rez_dict['model_6']\n",
        "# прохід для пошуку параметрів\n",
        "\n",
        "for cur_opt in l_optims:\n",
        "    for cur_batch in l_batchs:\n",
        "      model = tf.keras.models.Sequential([\n",
        "              tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "              #26*26\n",
        "              tf.keras.layers.MaxPooling2D(2, 2),\n",
        "              #13*13\n",
        "              tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "              #11*11\n",
        "              tf.keras.layers.MaxPooling2D(2, 2),\n",
        "              #5*5\n",
        "              tf.keras.layers.Dropout(0.2),\n",
        "              tf.keras.layers.Flatten(),\n",
        "              tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
        "              tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "              tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "              tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "              tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "              tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "                                          ])\n",
        "      model.compile(optimizer=cur_opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "      # Train the model\n",
        "      history = model.fit(training_images, training_labels, batch_size=cur_batch, epochs=50, callbacks=[callbacks])\n",
        "\n",
        "      # Evaluate on the test set\n",
        "      test_accuracy = model.evaluate(test_images, test_labels)\n",
        "      print(f'\\nMODEL 6. 2cov3_2plot_1drop_-1024-512-256-128-64-10 optimizer={cur_opt} batch_size={cur_batch}:')\n",
        "\n",
        "\n",
        "      #results\n",
        "      if rec['acc'] < test_accuracy[-1]:\n",
        "        rec['optim'] = cur_opt\n",
        "        rec['batch'] = cur_batch\n",
        "        rec['epoch'] = len(history.history['accuracy'])\n",
        "        rec['acc'] = test_accuracy[-1]\n",
        "\n",
        "print(rec)"
      ],
      "metadata": {
        "id": "hsO2DiHF-2Eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL 6. 2cov3_2plot_1drop_-1024-512-256-128-64-10 optimizer=Adam batch_size=500:\n",
        "{'optim': 'RMSprop', 'batch': 100, 'epoch': 50, 'acc': 0.9190999865531921}\n",
        "\n",
        " найкращій результат. можна навіть додатково збільшити кількість епох"
      ],
      "metadata": {
        "id": "6b6woEvPDE4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Результат частина 1\n",
        "# не забути запусти класс Mycallbacks\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# завантаження Fashion MNIST\n",
        "fmnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()\n",
        "\n",
        "\n",
        "training_images = training_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "                                    ])\n",
        "model.compile(optimizer='RMSprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(training_images,\n",
        "                    training_labels,\n",
        "                    batch_size=100,\n",
        "                    epochs=80,\n",
        "                    callbacks=[callbacks],\n",
        "                    validation_data=(test_images, test_labels),\n",
        "                    verbose = 1,\n",
        "                    validation_steps=3)\n",
        "\n",
        "acc = history.history[\"accuracy\"]\n",
        "val_acc = history.history[\"val_accuracy\"]\n",
        "\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(20, 7), dpi=80)\n",
        "plt.grid(True)\n",
        "\n",
        "plt.plot(epochs, acc, \"bo\", label=\"Training acc\")\n",
        "plt.plot(epochs, val_acc, \"b\", label=\"Validation acc\")\n",
        "\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "plt.figure(figsize=(20, 7), dpi=80)\n",
        "plt.grid(True)\n",
        "\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E0WrOnq2n0Zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Частина 2\n",
        "\n",
        "На відміну від попереднього завдання вам пропонується створити згорткову нейромережу, що використовує VGG16 в якості згорткової основи.\n",
        "\n",
        "Навчіть отриману мережу на даних із датасету fasion_mnist. Спробуйте досягти максимально можливої точності класифікації за рахунок маніпуляції параметрами мережі. Під час навчання використовуйте прийоми донавчання та виділення ознак.\n",
        "\n",
        "Порівняйте точність отриманої згорткової мережі з точністю багатошарової мережі з попереднього завдання. Зробіть висновки."
      ],
      "metadata": {
        "id": "cmVAF8gDvS5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import img_to_array, array_to_img\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "\n",
        "# завантаження Fashion MNIST\n",
        "fmnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()\n",
        "\n",
        "\n",
        "\n",
        "train_X = np.asarray([img_to_array(array_to_img(np.dstack([im.flatten()]*3).reshape((28,28,3)), scale=False).resize((48,48))) for im in training_images])\n",
        "test_X = np.asarray([img_to_array(array_to_img(np.dstack([im.flatten()]*3).reshape((28,28,3)), scale=False).resize((48,48))) for im in test_images])\n",
        "\n",
        "# нормалізація\n",
        "train_X = train_X / 255.0\n",
        "test_X = test_X / 255.0\n"
      ],
      "metadata": {
        "id": "N5JbilCuoufo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#перевірка сету\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.utils import img_to_array, array_to_img\n",
        "import random\n",
        "\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "\n",
        "plt.imshow(array_to_img(training_images[1].reshape((28,28,1))))\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(array_to_img(train_X[1]))\n",
        "print(train_X[1].shape)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B86B9PTAYeND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1./255,fill_mode='nearest')\n",
        "\n",
        "\n",
        "train_generator, validation_generator = datagen.flow_from_numpy(\n",
        "    x=training_images,\n",
        "    y=test_images,\n",
        "    target_size=(48, 48),\n",
        "    batch_size=200,\n",
        "    class_mode='categorical')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vSpvvd-KRtMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "# виділення ознак\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "conv_base = VGG16(weights=\"imagenet\", include_top=False, input_shape=(48, 48, 3))\n",
        "conv_base.trainable = False\n",
        "\n",
        "model = models.Sequential([\n",
        "   conv_base,\n",
        "   layers.Flatten(),\n",
        "   layers.Dense(256, activation=\"relu\"),\n",
        "   layers.Dense(10, activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001),\n",
        "    metrics=[\"accuracy\"]\n",
        "\n",
        "    )\n",
        "\n",
        "\n",
        "history = model.fit(train_X,\n",
        "                    training_labels,\n",
        "                    batch_size=200,\n",
        "                    epochs=50,\n",
        "                    validation_data=(test_X, test_labels),\n",
        "                    verbose = 1,\n",
        "                    validation_steps=3)\n",
        "\n",
        "# аналіз результатів\n",
        "\n",
        "acc = history.history[\"accuracy\"]\n",
        "val_acc = history.history[\"val_accuracy\"]\n",
        "\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(20, 7), dpi=80)\n",
        "plt.grid(True)\n",
        "\n",
        "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
        "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
        "\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "plt.figure(figsize=(20, 7), dpi=80)\n",
        "plt.grid(True)\n",
        "\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cjuvksH0vaLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# донавчання\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "\n",
        "conv_base = VGG16(weights=\"imagenet\", include_top=False, input_shape=(48, 48, 3))\n",
        "\n",
        "conv_base.trainable = True\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == \"block5_conv1\":\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "modified_model = models.Sequential([\n",
        "   conv_base,\n",
        "   layers.Flatten(),\n",
        "   layers.Dense(256, activation=\"relu\"),\n",
        "   layers.Dense(10, activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "modified_model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001),\n",
        "    metrics=[\"accuracy\"]\n",
        "\n",
        "    )\n",
        "\n",
        "\n",
        "history = modified_model.fit(train_X,\n",
        "                    training_labels,\n",
        "                    batch_size=200,\n",
        "                    epochs=50,\n",
        "                    validation_data=(test_X, test_labels),\n",
        "                    verbose = 1,\n",
        "                    validation_steps=3)\n",
        "\n",
        "\n",
        "\n",
        "# аналіз результатів\n",
        "\n",
        "acc = history.history[\"accuracy\"]\n",
        "val_acc = history.history[\"val_accuracy\"]\n",
        "\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(20, 7), dpi=80)\n",
        "plt.grid(True)\n",
        "\n",
        "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
        "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
        "\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "plt.figure(figsize=(20, 7), dpi=80)\n",
        "plt.grid(True)\n",
        "\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jlxfpfOZvvzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESUME:\n",
        "- власна модель.\n",
        " модель досягає цільового результату вже за 10-12 епох. Результат найкращій з усіх, проте є схильність до перенавчання\n",
        "\n",
        "- виділення ознак.\n",
        "Модель показала меншу точність, проте і контроль і навчальна виборка мають однакову тенденцію. Ця модель на мою думку найменше схильна до перенавчання\n",
        "\n",
        "- Донавчання.\n",
        "точність гірше ніж у власної моделі. досягнення теж вібдуваєть шкидше 6-8 епох потрібно. Висока схильність до перенавчання, після 10 епох.\n",
        "\n",
        "Важливе доповнення. Натренована модель, як показала перевірка з доповнення, навчається швидше й менше може перенавчатися, проте якість датасетів має бути співставна. Тобто в роботі брався сет з дуже слабовизначеними ознаками. Тож навіть навчана модельна такому датасеті краще результат не покаже."
      ],
      "metadata": {
        "id": "wL6MYpaJa3IY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yO2pN7D-vgni"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}